{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "OgBp_EzXqFr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "00c46cfc-8f1f-4461-f1e3-fad3944e9603"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7HHk424IKWOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e31b6b3-3556-4592-bf7d-08857c770672"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "from keras.layers import Dense, Input, LSTM, Bidirectional, Activation, Conv1D, GRU, TimeDistributed\n",
        "from keras.layers import Dropout, Embedding, GlobalMaxPooling1D, MaxPooling1D, Add, Flatten, SpatialDropout1D\n",
        "from keras.layers import GlobalAveragePooling1D, BatchNormalization, concatenate\n",
        "from keras.layers import Reshape, merge, Concatenate, Lambda, Average\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.initializers import Constant\n",
        "from keras.layers.merge import add\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qRSNQIlqL56-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/My Drive/data_science/text_mining/train_values.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmA6QVoPMJW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_lab=pd.read_csv('/content/gdrive/My Drive/data_science/text_mining/train_labels.csv', sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZrENilMAM6C-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['doc_text'])\n",
        "X = tokenizer.texts_to_sequences(df['doc_text'])\n",
        "df['words'] = X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tmJAwpn-PF4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df['word_length'] = df.words.apply(lambda i: len(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fIAzMzytOYIu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99581bed-e0c3-4b9a-a3ea-7f80389d890a"
      },
      "cell_type": "code",
      "source": [
        "df['word_length'] = df.words.apply(lambda i: len(i))\n",
        "df = df[df.word_length >= 5]\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['row_id', 'doc_text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "ITd3YjNSRIbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.words[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mpZ_uiBMO-e-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxlen = 50\n",
        "X = list(sequence.pad_sequences(df.words, maxlen=maxlen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXIeUG2rqB29",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i3zC-kz7T-hQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "adcc6fa1-ca71-4b6b-a6e2-435f9f30c93b"
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('/content/gdrive/My Drive/data_science/text_mining/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "print('Total %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 342859 unique tokens.\n",
            "Total 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bAU6p6k_UfOQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(len(word_index)+1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=maxlen,\n",
        "                            trainable=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VE32fXDjUpuf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y=pd.read_csv('/content/gdrive/My Drive/data_science/text_mining/train_labels.csv',sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "04VcoXh7U9Nn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "5e8bcf4d-ada6-46f2-e9b4-282dcf6cbef0"
      },
      "cell_type": "code",
      "source": [
        "Y.columns"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['row_id', 'information_and_communication_technologies', 'governance',\n",
              "       'urban_development', 'law_and_development', 'public_sector_development',\n",
              "       'agriculture', 'communities_and_human_settlements',\n",
              "       'health_and_nutrition_and_population', 'culture_and_development',\n",
              "       'environment', 'social_protections_and_labor', 'industry',\n",
              "       'macroeconomics_and_economic_growth',\n",
              "       'international_economics_and_trade', 'conflict_and_development',\n",
              "       'finance_and_financial_sector_development',\n",
              "       'science_and_technology_development', 'rural_development',\n",
              "       'poverty_reduction', 'private_sector_development', 'informatics',\n",
              "       'energy', 'social_development', 'water_resources', 'education',\n",
              "       'transport', 'water_supply_and_sanitation', 'gender',\n",
              "       'infrastructure_economics_and_finance'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "J-ed2bpXUyA_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y=Y.drop('row_id',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3JBgE_GvV1AP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2fd7c3f3-2df4-4b39-fe83-0162cdcb6b45"
      },
      "cell_type": "code",
      "source": [
        "Y.shape[1]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "jHb3rDloUlFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "\n",
        "\n",
        "# and split to training set and validation set\n",
        "\n",
        "seed = 29\n",
        "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EwEUOvwyqHAV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "5UjymuCcqNMw",
        "colab_type": "code",
        "outputId": "50ab1a6b-17db-498e-d06d-74467198f6a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 848
        }
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(maxlen,), dtype='int32')\n",
        "embedding = embedding_layer(inp)\n",
        "stacks = []\n",
        "for kernel_size in [2, 3, 4]:\n",
        "    conv = Conv1D(64, kernel_size, padding='same', activation='relu', strides=1)(embedding)\n",
        "    pool = MaxPooling1D(pool_size=3)(conv)\n",
        "    drop = Dropout(0.5)(pool)\n",
        "    stacks.append(drop)\n",
        "\n",
        "merged = Concatenate()(stacks)\n",
        "flatten = Flatten()(merged)\n",
        "drop = Dropout(0.5)(flatten)\n",
        "outp = Dense((Y.shape[1]), activation='softprop')(drop)\n",
        "\n",
        "TextCNN = Model(inputs=inp, outputs=outp)\n",
        "TextCNN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-53d8e4e06f7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mflatten\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdrop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moutp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softprop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mTextCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/activations.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         printable_module_name='activation function')\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 165\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown activation function:softprop"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-lEF4aTmWF1_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3454
        },
        "outputId": "722f69a7-2fd9-4b59-f6d2-74bf18d2f12c"
      },
      "cell_type": "code",
      "source": [
        "textcnn_history = TextCNN.fit(x_train, \n",
        "                              y_train, \n",
        "                              batch_size=128, \n",
        "                              epochs=100, \n",
        "                              validation_data=(x_val, y_val))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15064 samples, validate on 3766 samples\n",
            "Epoch 1/100\n",
            "15064/15064 [==============================] - 1s 93us/step - loss: 8.4580 - acc: 0.2127 - val_loss: 9.0045 - val_acc: 0.2116\n",
            "Epoch 2/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.4355 - acc: 0.2116 - val_loss: 9.0123 - val_acc: 0.1827\n",
            "Epoch 3/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.4129 - acc: 0.2122 - val_loss: 9.0056 - val_acc: 0.2114\n",
            "Epoch 4/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.3907 - acc: 0.2161 - val_loss: 9.0087 - val_acc: 0.1848\n",
            "Epoch 5/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.3671 - acc: 0.2169 - val_loss: 9.0058 - val_acc: 0.1845\n",
            "Epoch 6/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.3496 - acc: 0.2207 - val_loss: 9.0074 - val_acc: 0.1814\n",
            "Epoch 7/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.3319 - acc: 0.2185 - val_loss: 9.0013 - val_acc: 0.2018\n",
            "Epoch 8/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.3109 - acc: 0.2148 - val_loss: 9.0115 - val_acc: 0.1981\n",
            "Epoch 9/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.3069 - acc: 0.2193 - val_loss: 9.0133 - val_acc: 0.2050\n",
            "Epoch 10/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.2889 - acc: 0.2217 - val_loss: 9.0309 - val_acc: 0.2143\n",
            "Epoch 11/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.3000 - acc: 0.2213 - val_loss: 9.0310 - val_acc: 0.2191\n",
            "Epoch 12/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.2771 - acc: 0.2214 - val_loss: 9.0329 - val_acc: 0.1824\n",
            "Epoch 13/100\n",
            "15064/15064 [==============================] - 1s 84us/step - loss: 8.2608 - acc: 0.2169 - val_loss: 9.0273 - val_acc: 0.2292\n",
            "Epoch 14/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.2499 - acc: 0.2191 - val_loss: 9.0301 - val_acc: 0.2156\n",
            "Epoch 15/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.2357 - acc: 0.2250 - val_loss: 9.0080 - val_acc: 0.1904\n",
            "Epoch 16/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.2371 - acc: 0.2234 - val_loss: 9.0264 - val_acc: 0.1864\n",
            "Epoch 17/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.2059 - acc: 0.2275 - val_loss: 9.0305 - val_acc: 0.2249\n",
            "Epoch 18/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.2036 - acc: 0.2236 - val_loss: 9.0442 - val_acc: 0.1790\n",
            "Epoch 19/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.2114 - acc: 0.2232 - val_loss: 9.0257 - val_acc: 0.2215\n",
            "Epoch 20/100\n",
            "15064/15064 [==============================] - 1s 84us/step - loss: 8.1909 - acc: 0.2269 - val_loss: 9.0244 - val_acc: 0.1904\n",
            "Epoch 21/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.1783 - acc: 0.2300 - val_loss: 9.0242 - val_acc: 0.2071\n",
            "Epoch 22/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.1724 - acc: 0.2238 - val_loss: 9.0396 - val_acc: 0.1893\n",
            "Epoch 23/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.1340 - acc: 0.2315 - val_loss: 9.0503 - val_acc: 0.1891\n",
            "Epoch 24/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.1616 - acc: 0.2281 - val_loss: 9.0408 - val_acc: 0.1875\n",
            "Epoch 25/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.1640 - acc: 0.2284 - val_loss: 9.0361 - val_acc: 0.2055\n",
            "Epoch 26/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.1366 - acc: 0.2289 - val_loss: 9.0366 - val_acc: 0.2061\n",
            "Epoch 27/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.1363 - acc: 0.2311 - val_loss: 9.0404 - val_acc: 0.1944\n",
            "Epoch 28/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.1133 - acc: 0.2312 - val_loss: 9.0303 - val_acc: 0.1941\n",
            "Epoch 29/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.1240 - acc: 0.2274 - val_loss: 9.0222 - val_acc: 0.1930\n",
            "Epoch 30/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.1070 - acc: 0.2307 - val_loss: 9.0531 - val_acc: 0.1930\n",
            "Epoch 31/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0932 - acc: 0.2280 - val_loss: 9.0330 - val_acc: 0.2071\n",
            "Epoch 32/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0935 - acc: 0.2270 - val_loss: 9.0445 - val_acc: 0.1933\n",
            "Epoch 33/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0795 - acc: 0.2351 - val_loss: 9.0397 - val_acc: 0.1922\n",
            "Epoch 34/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0736 - acc: 0.2319 - val_loss: 9.0582 - val_acc: 0.2084\n",
            "Epoch 35/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0762 - acc: 0.2308 - val_loss: 9.0598 - val_acc: 0.2225\n",
            "Epoch 36/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0431 - acc: 0.2309 - val_loss: 9.0477 - val_acc: 0.2122\n",
            "Epoch 37/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0640 - acc: 0.2371 - val_loss: 9.0554 - val_acc: 0.1784\n",
            "Epoch 38/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 8.0473 - acc: 0.2344 - val_loss: 9.0596 - val_acc: 0.1954\n",
            "Epoch 39/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.0463 - acc: 0.2340 - val_loss: 9.0588 - val_acc: 0.2037\n",
            "Epoch 40/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0438 - acc: 0.2361 - val_loss: 9.0747 - val_acc: 0.1869\n",
            "Epoch 41/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0185 - acc: 0.2355 - val_loss: 9.0612 - val_acc: 0.2066\n",
            "Epoch 42/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0501 - acc: 0.2311 - val_loss: 9.0626 - val_acc: 0.2223\n",
            "Epoch 43/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0303 - acc: 0.2345 - val_loss: 9.0697 - val_acc: 0.1837\n",
            "Epoch 44/100\n",
            "15064/15064 [==============================] - 1s 84us/step - loss: 8.0136 - acc: 0.2379 - val_loss: 9.0784 - val_acc: 0.2193\n",
            "Epoch 45/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 8.0247 - acc: 0.2381 - val_loss: 9.0691 - val_acc: 0.2026\n",
            "Epoch 46/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0316 - acc: 0.2375 - val_loss: 9.0673 - val_acc: 0.1904\n",
            "Epoch 47/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0221 - acc: 0.2358 - val_loss: 9.0734 - val_acc: 0.1739\n",
            "Epoch 48/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 8.0023 - acc: 0.2327 - val_loss: 9.0797 - val_acc: 0.1999\n",
            "Epoch 49/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9904 - acc: 0.2382 - val_loss: 9.0842 - val_acc: 0.1819\n",
            "Epoch 50/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9971 - acc: 0.2353 - val_loss: 9.0758 - val_acc: 0.1944\n",
            "Epoch 51/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9965 - acc: 0.2359 - val_loss: 9.0827 - val_acc: 0.1907\n",
            "Epoch 52/100\n",
            "15064/15064 [==============================] - 1s 85us/step - loss: 7.9915 - acc: 0.2386 - val_loss: 9.0758 - val_acc: 0.1917\n",
            "Epoch 53/100\n",
            "15064/15064 [==============================] - 1s 85us/step - loss: 7.9726 - acc: 0.2377 - val_loss: 9.1010 - val_acc: 0.1880\n",
            "Epoch 54/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9912 - acc: 0.2461 - val_loss: 9.0958 - val_acc: 0.1872\n",
            "Epoch 55/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9676 - acc: 0.2360 - val_loss: 9.0910 - val_acc: 0.2066\n",
            "Epoch 56/100\n",
            "15064/15064 [==============================] - 1s 81us/step - loss: 7.9792 - acc: 0.2348 - val_loss: 9.0825 - val_acc: 0.1832\n",
            "Epoch 57/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9566 - acc: 0.2342 - val_loss: 9.1124 - val_acc: 0.1795\n",
            "Epoch 58/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9472 - acc: 0.2394 - val_loss: 9.0983 - val_acc: 0.2039\n",
            "Epoch 59/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9669 - acc: 0.2357 - val_loss: 9.1085 - val_acc: 0.1933\n",
            "Epoch 60/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9541 - acc: 0.2330 - val_loss: 9.0897 - val_acc: 0.1981\n",
            "Epoch 61/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9444 - acc: 0.2382 - val_loss: 9.0838 - val_acc: 0.1830\n",
            "Epoch 62/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9477 - acc: 0.2391 - val_loss: 9.1007 - val_acc: 0.2225\n",
            "Epoch 63/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9516 - acc: 0.2410 - val_loss: 9.1215 - val_acc: 0.1946\n",
            "Epoch 64/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9357 - acc: 0.2388 - val_loss: 9.1002 - val_acc: 0.1973\n",
            "Epoch 65/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9219 - acc: 0.2387 - val_loss: 9.1032 - val_acc: 0.1875\n",
            "Epoch 66/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9333 - acc: 0.2441 - val_loss: 9.0980 - val_acc: 0.1885\n",
            "Epoch 67/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9284 - acc: 0.2388 - val_loss: 9.1052 - val_acc: 0.2061\n",
            "Epoch 68/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9185 - acc: 0.2396 - val_loss: 9.1021 - val_acc: 0.2076\n",
            "Epoch 69/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9250 - acc: 0.2381 - val_loss: 9.1140 - val_acc: 0.1952\n",
            "Epoch 70/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9266 - acc: 0.2384 - val_loss: 9.0993 - val_acc: 0.1946\n",
            "Epoch 71/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8967 - acc: 0.2406 - val_loss: 9.1227 - val_acc: 0.2143\n",
            "Epoch 72/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9109 - acc: 0.2391 - val_loss: 9.1333 - val_acc: 0.1976\n",
            "Epoch 73/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9100 - acc: 0.2371 - val_loss: 9.1295 - val_acc: 0.1814\n",
            "Epoch 74/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8902 - acc: 0.2440 - val_loss: 9.1127 - val_acc: 0.1837\n",
            "Epoch 75/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.9019 - acc: 0.2485 - val_loss: 9.1195 - val_acc: 0.1803\n",
            "Epoch 76/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.9061 - acc: 0.2377 - val_loss: 9.1333 - val_acc: 0.1827\n",
            "Epoch 77/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8926 - acc: 0.2450 - val_loss: 9.1157 - val_acc: 0.1957\n",
            "Epoch 78/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8884 - acc: 0.2429 - val_loss: 9.1349 - val_acc: 0.1888\n",
            "Epoch 79/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8884 - acc: 0.2391 - val_loss: 9.1388 - val_acc: 0.2100\n",
            "Epoch 80/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8792 - acc: 0.2456 - val_loss: 9.1288 - val_acc: 0.1872\n",
            "Epoch 81/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8874 - acc: 0.2394 - val_loss: 9.1268 - val_acc: 0.2037\n",
            "Epoch 82/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8765 - acc: 0.2387 - val_loss: 9.1092 - val_acc: 0.2031\n",
            "Epoch 83/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8705 - acc: 0.2437 - val_loss: 9.1570 - val_acc: 0.2066\n",
            "Epoch 84/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8784 - acc: 0.2459 - val_loss: 9.1427 - val_acc: 0.1925\n",
            "Epoch 85/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8872 - acc: 0.2428 - val_loss: 9.1140 - val_acc: 0.1957\n",
            "Epoch 86/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8725 - acc: 0.2422 - val_loss: 9.1281 - val_acc: 0.2010\n",
            "Epoch 87/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8585 - acc: 0.2417 - val_loss: 9.1417 - val_acc: 0.2037\n",
            "Epoch 88/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8808 - acc: 0.2403 - val_loss: 9.1357 - val_acc: 0.1864\n",
            "Epoch 89/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8842 - acc: 0.2413 - val_loss: 9.1388 - val_acc: 0.2087\n",
            "Epoch 90/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8390 - acc: 0.2404 - val_loss: 9.1353 - val_acc: 0.2082\n",
            "Epoch 91/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8557 - acc: 0.2422 - val_loss: 9.1668 - val_acc: 0.1859\n",
            "Epoch 92/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8420 - acc: 0.2426 - val_loss: 9.1307 - val_acc: 0.1922\n",
            "Epoch 93/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8455 - acc: 0.2418 - val_loss: 9.1264 - val_acc: 0.2223\n",
            "Epoch 94/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8448 - acc: 0.2481 - val_loss: 9.1441 - val_acc: 0.1917\n",
            "Epoch 95/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8502 - acc: 0.2426 - val_loss: 9.1561 - val_acc: 0.1843\n",
            "Epoch 96/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8312 - acc: 0.2458 - val_loss: 9.1448 - val_acc: 0.1888\n",
            "Epoch 97/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8321 - acc: 0.2501 - val_loss: 9.1697 - val_acc: 0.2007\n",
            "Epoch 98/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8487 - acc: 0.2426 - val_loss: 9.1474 - val_acc: 0.1856\n",
            "Epoch 99/100\n",
            "15064/15064 [==============================] - 1s 82us/step - loss: 7.8403 - acc: 0.2461 - val_loss: 9.1366 - val_acc: 0.2039\n",
            "Epoch 100/100\n",
            "15064/15064 [==============================] - 1s 83us/step - loss: 7.8325 - acc: 0.2398 - val_loss: 9.1381 - val_acc: 0.1949\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7bOyz_gTtnxa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predicted = TextCNN.predict(x_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CpV0RRLQXs_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save=pd.DataFrame(predicted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jaHbkrZHYZLE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save.to_csv('/content/gdrive/My Drive/data_science/text_mining/123.csv',sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FgPHjeMYtuu8",
        "colab_type": "code",
        "outputId": "bc5833b7-5976-4d31-8b98-d762c2cc96fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "np.where(y_val.iloc[0,:]==1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([12, 13, 15, 19]),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "2vn3bjCKcyGK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "34219762-c773-4c98-b298-33aabd594989"
      },
      "cell_type": "code",
      "source": [
        "y_val.iloc[0,:]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "information_and_communication_technologies    0\n",
              "governance                                    0\n",
              "urban_development                             0\n",
              "law_and_development                           0\n",
              "public_sector_development                     0\n",
              "agriculture                                   0\n",
              "communities_and_human_settlements             0\n",
              "health_and_nutrition_and_population           0\n",
              "culture_and_development                       0\n",
              "environment                                   0\n",
              "social_protections_and_labor                  0\n",
              "industry                                      0\n",
              "macroeconomics_and_economic_growth            1\n",
              "international_economics_and_trade             1\n",
              "conflict_and_development                      0\n",
              "finance_and_financial_sector_development      1\n",
              "science_and_technology_development            0\n",
              "rural_development                             0\n",
              "poverty_reduction                             0\n",
              "private_sector_development                    1\n",
              "informatics                                   0\n",
              "energy                                        0\n",
              "social_development                            0\n",
              "water_resources                               0\n",
              "education                                     0\n",
              "transport                                     0\n",
              "water_supply_and_sanitation                   0\n",
              "gender                                        0\n",
              "infrastructure_economics_and_finance          0\n",
              "Name: 8328, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "xLYlzu08tn5v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "collist=list(y_val.columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CRSA3jDEbxxy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "129cdc69-63ff-46f3-f221-5c83f06cf34f"
      },
      "cell_type": "code",
      "source": [
        "collist[12]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'macroeconomics_and_economic_growth'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "ITrlk1_uRuUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir  picture"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YoBi7i7VTsTd",
        "colab_type": "code",
        "outputId": "f9f7eafa-dc22-4a10-b400-6ce2e5b773b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "cell_type": "code",
      "source": [
        "rm --help"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Usage: rm [OPTION]... [FILE]...\n",
            "Remove (unlink) the FILE(s).\n",
            "\n",
            "  -f, --force           ignore nonexistent files and arguments, never prompt\n",
            "  -i                    prompt before every removal\n",
            "  -I                    prompt once before removing more than three files, or\n",
            "                          when removing recursively; less intrusive than -i,\n",
            "                          while still giving protection against most mistakes\n",
            "      --interactive[=WHEN]  prompt according to WHEN: never, once (-I), or\n",
            "                          always (-i); without WHEN, prompt always\n",
            "      --one-file-system  when removing a hierarchy recursively, skip any\n",
            "                          directory that is on a file system different from\n",
            "                          that of the corresponding command line argument\n",
            "      --no-preserve-root  do not treat '/' specially\n",
            "      --preserve-root   do not remove '/' (default)\n",
            "  -r, -R, --recursive   remove directories and their contents recursively\n",
            "  -d, --dir             remove empty directories\n",
            "  -v, --verbose         explain what is being done\n",
            "      --help     display this help and exit\n",
            "      --version  output version information and exit\n",
            "\n",
            "By default, rm does not remove directories.  Use the --recursive (-r or -R)\n",
            "option to remove each listed directory, too, along with all of its contents.\n",
            "\n",
            "To remove a file whose name starts with a '-', for example '-foo',\n",
            "use one of these commands:\n",
            "  rm -- -foo\n",
            "\n",
            "  rm ./-foo\n",
            "\n",
            "Note that if you use rm to remove a file, it might be possible to recover\n",
            "some of its contents, given sufficient expertise and/or time.  For greater\n",
            "assurance that the contents are truly unrecoverable, consider using shred.\n",
            "\n",
            "GNU coreutils online help: <http://www.gnu.org/software/coreutils/>\n",
            "Full documentation at: <http://www.gnu.org/software/coreutils/rm>\n",
            "or available locally via: info '(coreutils) rm invocation'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CBkkXuDsw02I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ]
    },
    {
      "metadata": {
        "id": "JmOszZfLRtsJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T0Q7klpKw1Gw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ]
    }
  ]
}