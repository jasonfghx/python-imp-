import pandas as pd

from glob import glob

import os

import tensorflow as tf



import numpy as np

import matplotlib.pyplot as plt

from PIL import Image

from keras.utils import np_utils

from keras.preprocessing import image

from __future__ import print_function

import keras



from keras.preprocessing.image import ImageDataGenerator

from keras.models import Sequential

from keras.layers import Dense, Dropout, Activation, Flatten

from keras.layers import Conv2D, MaxPooling2D

from itertools import chain



all_xray_df = pd.read_csv('Data_Entry_2017.csv')#set E:\temp  first



all_xray_df=all_xray_df.drop('Unnamed: 11',axis = 1)

#data frame 可以透過 drop() 方法來刪除觀測值或欄位，指定參數 axis = 0 表示要刪除觀測值（row），指定參數 axis = 1 表示要刪除欄位（column）。

"""

all_xray_df.columns

Out[213]: 

Index(['Image Index', 'Finding Labels', 'Follow-up #', 'Patient ID',

       'Patient Age', 'Patient Gender', 'View Position', 'OriginalImage[Width',

       'Height]', 'OriginalImagePixelSpacing[x', 'y]', 'Unnamed: 11'],

      dtype='object')

"""



all_image_paths = {os.path.basename(x): x for x in glob(r'D:\hw\images\*.png')}# get address of image

data=all_xray_df.drop(all_xray_df.index[4999:112120])

data['path'] = data['Image Index'].map(all_image_paths.get)

print('Scans found:', len(data), ', Total Headers', data.shape[0])

label_counts = data['Finding Labels'].value_counts()[:15]

pull1=np.where(data["Finding Labels"]!="No Finding")[0]



temp=pd.DataFrame()

for i in range(0,2244):

    temp[i,]=data.iloc[pull1[i],:]



temp=temp.T



data = pd.concat([data, temp], axis=0, ignore_index=True)#merge

data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))

from itertools import chain

all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))

all_labels1 = [x for x in all_labels if len(x)>0]

print('All Labels ({}): {}'.format(len(all_labels1), all_labels1))

for c_label in all_labels1:

    if len(c_label)>1: # leave out empty labels

        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)

MIN_CASES = 100

all_labels2 = [c_label for c_label in all_labels1 if data[c_label].sum()>MIN_CASES]

print('Clean Labels ({})'.format(len(all_labels2)), 

      [(c_label,int(data[c_label].sum())) for c_label in all_labels2])



data1=data.drop('Hernia',axis = 1)
data1=data1.drop(['Edema',"Pneumonia"],axis = 1)
data1=data1.drop('Edema',"Pneumonia",axis = 1)
data2=data

data1['disease_vec'] = data1.apply(lambda x: [x[all_labels2].values], 1).map(lambda x: x[0])

from sklearn.model_selection import train_test_split

train_df, valid_df = train_test_split(data1, 

                                   test_size = 0.2, 

                                   random_state = 2018)

                                   

print('train', train_df.shape[0], 'validation', valid_df.shape[0])

"the is train"



label1= pd.DataFrame()
dataim=np.empty((3999,256,256,3),dtype="float32")

for i in range(0,3999):

        img = Image.open(train_df.iloc[i,11])

        arr = np.asarray(img, dtype="float32")

        arr.resize((256,256,3))

        dataim[i, :, :, :] = arr

        label1[i] = train_df.iloc[i,23]

 

    

"the is test"    



dataimtest=np.empty((1000,256,256,3),dtype="float32")

label1test= pd.DataFrame()

for i in range(0,1000):

        img = Image.open(valid_df.iloc[i,11])

        arr = np.asarray(img, dtype="float32")

        arr.resize((256,256,3))

        dataimtest[i, :, :, :] = arr

        label1test[i] = valid_df.iloc[i,13:26]

x_train=dataim/255

y_train=label1.T





x_test=dataimtest/255

y_test=label1test.T



model = Sequential()

model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))

model.add(Activation("sigmoid"))

model.add(Conv2D(32, (3, 3)))

model.add(Activation("sigmoid"))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.75))



model.add(Conv2D(64, (3, 3), padding='same'))

model.add(Activation("sigmoid"))

model.add(Conv2D(64, (3, 3)))

model.add(Activation("sigmoid"))

model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Dropout(0.25))



model.add(Flatten())



model.add(Activation("sigmoid"))

model.add(Dropout(0.5))

model.add(Dense(11))

model.add(Activation('softmax'))



opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)



model.compile(loss='categorical_crossentropy',

              optimizer="adam",

              metrics=['accuracy'])

histroy=model.fit(x_train, y_train,

              batch_size=30,

              epochs=1,

              #callbacks=[history],

               validation_data=(x_test, y_test),

              shuffle=True)



#predict

predict=model.predict(x_test)
